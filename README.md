# Programming-the-Dataflow-for-BIG-DATA-Analytics-using-APACHE-SPARK

1. Program a word-co-occurrence program in Spark and test it for n=2 (n-grams) and just 1 or 2 documents. Scale it up for as many documents as possible.

2. This problem was provided by researchers in the Classics department at UB. They have provided two classical texts and a lemmatization file to convert words from one form to a standard or normal form. 

3. Pass 1: Lemmetization using the lemmas.csv file

4. Pass 2: Identify the words in the texts by <word <docid, [chapter#, line#]> for two documents.

5. Pass 3: Repeat this for multiple documents.


Language: Scala
